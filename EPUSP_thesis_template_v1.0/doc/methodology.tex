\chapter{Methodology} \label{chap:method}

Introduction here...

% ****************************************************************************
% ******************	NOTATION section
% ****************************************************************************
%
\section{Notation and definitions} \label{notation}
Throughout this work the $n$-dimensional real Euclidean space will be denoted 
by $\mathbb{R}^{n}$ and the linear space of all $m \times n$ real matrices by 
$\mathbb{B}(\mathbb{R}^{n},\mathbb{R}^{m})$,  with $\mathbb{B}
(\mathbb{R}^{n})$\,$:=$\,$\mathbb{B}(\mathbb{R}^{n},\mathbb{R}^{n})$.

We denote by $\mathbb{H}^{n,m}$ the linear space made up of all $N$-sequences 
of real matrices $V$\,$=$\,$(V_{1},\dotsc,V_{N})$ with $V_{i}$\,$\in$\,
$\mathbb{B}(\mathbb{R}^{n},\mathbb{R}^{m})$, for $i$\,$=$\,$1,\dotsc,N$ and, 
for simplicity, set $\mathbb{H}^{n}$\,$:=$\,$\mathbb{H}^{n,n}$. 

We say that $V$\,$=$\,$(V_{1},\dotsc,V_{N})$\,$\in$\,$\mathbb{H}^{n+}$ if $V$\,
$\in$\,$\mathbb{H}^{n}$ and $V_{i}$\,$\geqslant$\,$0$, for each $i$\,$=$\,$1,
\dotsc,N$. 
The space of all bounded linear operators from $\mathbb{H}^{n}$ to 
$\mathbb{H}^{m}$ will be represented by $\mathbb{B}(\mathbb{H}^{n},
\mathbb{H}^{m})$ and, in particular, $\mathbb{B}(\mathbb{H}^{n})$\,$:=$\,
$\mathbb{B}(\mathbb{H}^{n},\mathbb{H}^{n})$.

We use the standard notation for $tr(A)$, $A'$, and $A^{\dagger}$ to represent 
the trace, transpose, and Moore-Penrose inverse of $A$ respectively.

The Kronecker product between two matrices $A$ and $B$ will be denoted by $A$\,
$\otimes$\,$B$, and the identity matrix (of appropriate dimension from the 
context) will be represented by $I$.

For a sequence of $n$-dimensional square matrices $A(0),\dotsc,A(t)$, we use 
the notation: 
%
\begin{flalign*}
	\prod_{l=s}^{t}A(l) =
	\begin{cases}
		A(t)\dotsm A(s) \text{ for } t \geqslant s, \\
		I \text{ for } t<s.
	\end{cases} 
\end{flalign*}

For a set $S$ we define $1_{s}$ as the usual indicator function, that is, 
%
\begin{flalign*}
	1_{s}(\omega) = 
	\begin{cases}
		1  \text{ if } \omega \in S, \\
		0 \text{ otherwise}. 
	\end{cases} 
\end{flalign*}

% ****************************************************************************
% ******************	MJLS section
% ****************************************************************************
%
\section{The linear system with Markov jumps and multiplicative noises} \label{MJLS}

We consider the following linear system with multiplicative noises and Markov 
jumps on a probabilistic space $(\Omega,\textbf{P},\mathcal{F})$ for $k=0, 
\cdots, T-1$ and $t=1, \cdots, T$:

\begin{flalign} \label{eq:system}
	x(k+1) ={}& \biggl[\: \bar{A}_{\theta(k)}(k)\;+\; 	
		\sum^{\varepsilon^{x}}_{s=1} \tilde{A}_{\theta(k),s}(k)w^{x}_{s}(k) 
		\:\biggr]x(k) 
	+\biggl[\:\bar{B}_{\theta(k)}(k)\;+\;\sum^{\varepsilon^{u}}_{s=1} 					\tilde{B}_{\theta(k),s}(k)w^{u}_{s}(k)\:\biggr]u(k), & \nonumber \\
	 x(0) ={}& x_{0}, \; \theta(0) = \theta_{0},&
\end{flalign}
%
\begin{flalign} \label{eq:output} 
	& y(t)=L_{\theta(t)}(t)x(t), &
\end{flalign}
where $L_{\theta(t)}(t) \in \mathbb{H}^{1,n}$.

Here, $s$  refers to the $s^{th}$ column vector  and $\theta(k)$ denotes the 
operation modes of a time-varying Markov chain taking values in \{1,$\dotsc$,N\} with transition probability matrix $\mathbb{P}(k)$ = $[\textit{p}_\textit{ij}(k)]$.

We define $\mathcal{F}_{\tau}$ as the $\sigma$-field generated by 
$\{(\theta(s),x(s));s$\,$=$\ $0,\dotsc,\tau \}$, $\mathcal{F}_{k}$ - measurable 
for each $k = \tau, \cdots, T-1$ and write $\mathbb{U}(\tau)$ $=$ 
$\{u_{\tau}$\,$=$\ $( u(\tau),\dotsc,u(T-1) )\}$, where $u(k)$ is an $m$-dimensional 
random vector with finite second moments.

Without loss of generality, we assume that $\varepsilon$\,$=$\,
$\varepsilon^{x}$\,$=$\,$\varepsilon^{u}$, and the superscript $^{u}$ will 
indicate that the control law $u$ is being applied to (\ref{eq:system}) and 
(\ref{eq:output}).

We have that, for each $s$ $=$ $1,\dotsc,\varepsilon$ and $k = 0,1,\cdots, T$,
\begin{flalign*}
	&\bar{A}(k) = (\bar{A}_{1}(k),\dotsc,\bar{A}_{N}(k)) \in \mathbb{H}^{n}, \\
	&\tilde{A}_{s}(k) = (\tilde{A}_{s,1}(k), \dotsc,\tilde{A}_{s,N}(k)) \in 	\mathbb{H}^{n}, \\ 
	&\bar{B}(k) = (\bar{B}_{1}(k), \dotsc, \bar{B}_{N}(k)) \in \mathbb{H}^{m,n}, \\ 
	&\tilde{B}_{s}(k) = (\tilde{B}_{s,1}(k),\dotsc,\tilde{B}_{s,N}(k)) \in \mathbb{H}^{m,n}.
\end{flalign*}

The multiplicative noises 
$\{w_{s}^{x}(k)$; $s$ $=$ $1,\dotsc,\varepsilon^{x}$, $k$ $=$ $0,1,\dotsc,T$ 
$-$ $1\}$ and 
$\{w_{s}^{u}(k)$; $s$ $=$ $1,\dotsc,\varepsilon^{u}$, $k$ $=$ $0,1,\dotsc,T$ 
$-$ $1\}$ 
are both zero-mean random variables with variance equal to 1 and also independent of the Markov chain $\{\theta(k)\}$.
The independence among their elements are set as $E[w^{x}_{i}(k)w^{x}_{j}(l)]=0$ and $E[w^{u}_{i}(k)w^{u}_{j}(l)]=0$, $\forall$ $k=l$ and $i\neq j$, or $\forall$ $k\neq l$ and $\forall$\,$i,j$. 

The mutual correlation between $w^{x}_{s1}(k)$ and $w^{u}_{s2}(k)$ is denoted 
by $E[w^{x}_{s1}(k)w^{u}_{s2}(k)]=\rho_{s1,s2}(k)$. 

The initial conditions $\theta_{0}$ and $x_{0}$ are assumed to be independent 
of $\{w_{s}^{x}(k)\}$ and $\{w_{s}^{u}(k)\}$, with $x_{0}$ an $n$-dimensional 
random vector with finite second moments. 

We also set the following expected values regarding the state variable.
\begin{flalign*}
	& \mu_{i}(0) = E(x_{0}1_{\{\theta_{0}=i\}}), \\
	& \mu(0) = [\mu_{1}(0)'\;\dotsc \; \mu_{N}(0)']\ \in \mathbb{H}^{n,1}, \\ 
	& Q_{i}(0) = E(x_{0}x_{0}'1_{\{\theta_{0}=i\}}),  \text{ and }\\
	& Q(0)= [Q_{1}(0)\;\dotsc\;Q_{N}(0)] \in \mathbb{H}^{n+}.
\end{flalign*}


% ****************************************************************************
% ******************	OBJECTIVE FORMULATION section
% ****************************************************************************
%
\section{The constrained problem formulation, $PC(\nu,\beta,\alpha)$} \label{obj_formul}

Our goal in this work is to find the optimal control policy, $u$, to the constrained problem denoted by $PC(\nu,\beta,\alpha)$ and defined as:
%
\begin{flalign} \label{PC3}
	& PC(\nu,\beta,\alpha): \max_{u \in \mathbb{U}} \sum_{t=1}^{T} \biggl[ 	
	\beta(t)E\big[ y^{u}(t) \big] \biggr],  \nonumber \\
	& \text{subject to:} \quad \sum_{t=1}^{T} \nu(t)Var\big[ y^{u}(t) \big] \leqslant \alpha,
\end{flalign}
%
where 
$ \beta = [\beta(1) \cdots \beta(T)]', \; \beta(t) \geqslant 0$, is the input 
parameter associated with system's output, $\nu=[\nu(1) \cdots \nu(T) ]',\; \nu(t) \geqslant 0$, is the input parameter associated with the variance of the system's output, 
and $\alpha \geqslant 0$ is the maximum total weighted variance of the system's output.

In this problem, the parameters $\beta$, $\nu$, and $\alpha$ are provided by the user and can be seen as risk aversion coefficients reflecting a trade-off preference between the expected output and the associated risk (variance) level.

%In this problem, the parameters $\nu$, $\beta$, and $\alpha$ are inputs provided by the user and in accordance with his/her risk preferences.
It is worth to mention that there is no formula to compute these parameters and they depend on the user's sensibility and capacity to "translate" risk aversion preferences between the 
expected output and the associated variance level into coefficients we can use in our model.

To assist someone on the task of computing these coefficients, we provide in Section \ref{s2} and Appendix \ref{app:E} a detailed sensitivity analysis regarding $\nu$ and $\beta$ for a certain level of $\alpha$.
However, just to illustrate the effects of these coefficients, we will also provide the following rather simple example.

Let's assume that $y^u(t)$ represents the absolute value, in monetary terms, of a portfolio of risk investment securities, where $u$ corresponds to the optimal allocation of the assets over the period of time $T$.
For simplicity, we will only consider a three-week period, $T=3$, an initial portfolio's value  of $\$1,000$, and that the investor wishes to limit the total variance of the portfolio's value to $\$30$ over the three-week period.

Let's also consider, in our example, that the investor is less averse to fluctuations in the expected value of the portfolio in the first week than in the the last two weeks by a multiple of $1.4$.
In the same way, consider that he/she is more averse to fluctuations in the variance in the second week  than in the first or third week by a multiple of $1.7$.


In this way, the investor could define $\alpha = 30$,  $\beta = [1.4\; 1\; 1]$, and $\nu = [1 \;1.7\; 1]$ in order to take into consideration the aversion towards risks as stated in the specific example above and to find an optimal allocation using $PC(\nu,\beta,\alpha)$.

Note that the relative weights between the elements of $\nu$ and $\beta$ are also relevant.
%
However, as we will see in Chapter \ref{chap:res}, when we impose a total weighted variance $\alpha$, there must be an adjustment between these relative weights in order to accommodate the new restriction on the variance. % with a correspondent new proper level 
%
Intuitively, if we want to fix a lower total variance it could only be achieved if we accept lower returns and conversely, if we want to fix a higher total variance it could only be achieved if we "accept" higher returns. 

Notwithstanding, lower or higher returns can be set by adjusting the coefficients of $\beta$ as we will see when we present the solution of $PC(\nu,\beta,\alpha)$ in Chapter \ref{chap:res}.
Thereby, our objective can be rephrased to finding the exactly expected level of the output that leads to the desired total weighted variance restriction, $\alpha$, which in turn can be achieved by properly adjusting $\beta$.


% ****************************************************************************
% ******************	PU problem section
% ****************************************************************************
%
\section{The unconstrained problem formulation, $PU(\nu,\xi)$} \label{uproblem}

The mean-variance cost function is defined as, for all $u \in \mathbb{U}$,
%
\begin{flalign} \label{costU}
	 \mathcal{C}(u) := \sum_{t=1}^{T} \biggl[ \nu(t)Var\big[ y^{u}(t) \big] 
	 -\xi(t)E\big[ y^{u}(t) \big] \biggr],
\end{flalign}
where $\xi=[\xi(1) \cdots \xi(T) ]',\;\xi(t) \geqslant 0$, is the input parameter associated with the system's output and $\nu(t) \geqslant 0$ is the input parameter as defined in problem (\ref{PC3}).
In the same way as in problem (\ref{PC3}), the input parameters $\xi$ and $\nu$ can be seen as risk aversion coefficients reflecting a trade-off preference between the expected output and the associated risk (variance) level, respectively.

The optimal control strategy of problem $PC(\nu,\beta,\alpha)$ will be obtained through the solution of the mean-variance unconstrained problem denoted by $PU(\nu,\xi)$ and defined as:
%
\begin{flalign} \label{PU}
	PU(\nu,\xi):\; \min_{u \in \mathbb{U}} \mathcal{C}(u).
\end{flalign}

Since problem $PU(\nu,\xi)$ involves a nonlinear function of an expectation 
term in $Var\big[ y^{u}(t) \big] = E\big[ y^{u}(t)^{2} \big] - E\big[  y^{u}(t) 
\big]^{2}$, it cannot be directly solved by dynamic programming and the 
following tractable auxiliary problem is solved instead.
%
\begin{flalign} \label{AP}
	 A(\nu, \lambda):=\; \min_{ u \in \mathbb{U} } E \Biggl\{ \sum_{t=1}^{T}\biggl[ \nu(t)y^{u}	
	(t)^{2} - \lambda(t)y^{u}(t) \biggr] \Biggr\} ,
\end{flalign}
%
where $\lambda=[\lambda(1) \cdots \lambda(T) ]',\; \lambda(t) \geqslant 0$.

Thus, the solution of problem (\ref{AP}) leads to the same solution of problem (\ref{PU}) and the reader is referred to \cite{alexandre} for more detailed information and proofs.

% ****************************************************************************
% ******************	Mathematical operators section
% ****************************************************************************
%
\section{Mathematical operators} \label{operators}

For $k$\,$=$\,$0,\dotsc,T-1$, $X$\,$\in$\,$\mathbb{H}^{n}$, and $i$\,$=$\,$1,\dotsc,N$ the following operators will be useful in the sequel to obtain the optimal control strategy of Problem (\ref{PU}) through the solution of Problem (\ref{AP}). 
%
\\ $\bullet$ \textbf{Expected value operator,} $\mathcal{E}(k,\cdot)$: \\
$\mathcal{E}(k,\cdot) \in \mathbb{B}(\mathbb{H}^{n}):$
\begin{flalign} \label{eq:pv}
	 \mathcal{E}_{i}(k,X)=\sum_{j=1}^{N}p_{ij}(k)X_{j}. 
\end{flalign}
%
$\bullet$ \textbf{Auxiliary operators}, $\mathcal{A}(k,\cdot)$, $\mathcal{G}(k,\cdot)$, and $\mathcal{R}(k,\cdot)$: \\
$\mathcal{A}(k,\cdot) \in \mathbb{B}(\mathbb{H}^{n}):$
\begin{flalign} \label{eq:Ai}
%E[ A(k)'X_{\theta(k+1)}A)k) | \mathcal{F}_k ]\equiv
	\mathcal{A}_{i}
		(k,X)=\bar{A}_{i}(k)'\mathcal{E}_{i}(k,X)\bar{A}_{i}(k) 
	+\sum_{s=1}^{\varepsilon}\tilde{A}_{i,s}(k)'\mathcal{E}_{i}	
		(k,X)\tilde{A}_{i,s}(k).
\end{flalign}
%
$\mathcal{G}(k,\cdot) \in \mathbb{B}(\mathbb{H}^{n,1},\mathbb{H}^{n,m}):$
\begin{flalign} \label{eq:Gi}
	\mathcal{G}_{i}(k,X)= \Biggl[ \bar{A}_{i}(k)' 
	 \mathcal{E}_{i}(k,X) \bar{B}_{i}(k) + \sum_{s1=1}^{\varepsilon} 
	\sum_{s2=1}^{\varepsilon} \rho_{s1,s2}(k) \tilde{A}_{i,s1}(k)' 
	\mathcal{E}_{i}(k,X) \tilde{B}_{i,s2}(k)\Biggr]'. 
\end{flalign}
%
$\mathcal{R}(k,\cdot)  \in \mathbb{B}(\mathbb{H}^{n},\mathbb{H}^{m}):$
\begin{flalign} \label{eq:Ri}
	\mathcal{R}_{i}(k,X)=\bar{B}_{i}(k)'\mathcal{E}_{i}(k,X)
	\bar{B}_{i}(k)+\sum_{s=1}^{\varepsilon}\tilde{B}_{i,s}(k)'\mathcal{E}_{i}
	(k,X)\tilde{B}_{i,s}(k).
\end{flalign}
%
$\bullet$ \textbf{Operator associated with the feedback gain of the optimal control law}, $\mathcal{K}(k,\cdot)$:
\begin{flalign} \label{eq:Ki}\
	\mathcal{K}_{i}(k,X)=\mathcal{R}_{i}(k,X)^{\dagger}\mathcal{G}_{i}(k,X), 
	 \text{ and } \nonumber \\ K_{i}(k)={}&\mathcal{K}_{i}(k,P(k+1)).
\end{flalign}
%
$\bullet$ \textbf{Operator associated with the generalized coupled Riccati difference equation}, $\mathcal{P}(k,\cdot)$:
\begin{flalign} \label{eq:Pi}
	\mathcal{P}_{i}(k,X)=\mathcal{A}_{i}(k,X)-\mathcal{G}_{i}(k,X)' 
	\mathcal{R}_{i}(k,X)^{\dagger}\mathcal{G}_{i}(k,X)
	+\nu(k)L_{i}(k)'L_{i}(k), \text{ and } \nonumber \\
	P_{i}(k) = \mathcal{P}_{i}(k,P(k+1)).
\end{flalign}
%
$\bullet$ \textbf{Operators related to the presence of the linear term in problem (\ref{AP})}, $\mathcal{V}(k,\cdot,\cdot)$ and $\mathcal{H}(k,\cdot)$: \\
$\mathcal{V}(k,\cdot,\cdot) \in \mathbb{B}(\mathbb{H}^{n,1},\mathbb{H}^{n,m}):$
\begin{flalign} \label{eq:Vi}
	\mathcal{V}_{i}(k,X,V)=\mathcal{E}_{i}(k,V) \bigl[ \bar{A}_{i}(k) 
	-\bar{B}_{i}(k)\mathcal{K}_{i}(k,X) \bigr] + \lambda(k)L_{i}(k), 
	\text{ and} \nonumber \\
	V_{i}(k)= \mathcal{V}_{i}(k,P(k+1),V(k+1)).
\end{flalign}
%
$\mathcal{H}(k,\cdot) \in \mathbb{B}(\mathbb{H}^{n,1},\mathbb{H}^{n,m}):$
\begin{flalign} \label{eq:Hfi}
	\mathcal{H}_{i}(k,V)
	=\bar{B}_{i}(k)'\mathcal{E}_{i}(k,V)', \text{ and} \nonumber \\
	 H_{i}(k)= \mathcal{H}_{i}(k,V(k+1)).
\end{flalign}

The following definitions are used to obtain a simplified formula for some parameters that will be used in the sequel.
\begin{flalign} \label{eq:gamma}
		\Gamma = 
		\left[
		\begin{matrix}
			\nu(1) & \cdots & 0\\
			\vdots & \ddots & \vdots \\
			0 & \cdots & \nu(T)
		\end{matrix}
		\right].
\end{flalign}

\begin{flalign} \label{eq:Av}
	 A_{i}^{cl}(k) = \bar{A}_{i}(k)-\bar{B}_{i}(k)K_{i}(k),  \nonumber \\
	\mathbb{A}(k) = 
	\left[
	\begin{matrix}
		p_{11}(k)A_{1}^{cl}(k) & \cdots & p_{N1}(k)A_{N}^{cl}(k)\\
		\vdots & \ddots & \vdots \\
		p_{1N}(k)A_{1}^{cl}(k) & \cdots & p_{NN}(k)A_{N}^{cl}(k)
	\end{matrix} 
	\right].
\end{flalign}

\begin{flalign} \label{eq:Dv}
	\mathbb{Q}_{i}(k) = \pi_{i}(k)\bar{B}_{i}(k)\mathcal{R}_{i}	
	(k,P(k+1))^{\dagger}\bar{B}_{i}(k)' \geqslant 0,  \nonumber \\
	\mathbb{D}(k) = 
	\left[
	\begin{matrix}
		\mathbb{Q}_{1}(k) & \cdots & 0\\
		\vdots & \ddots & \vdots \\
		0 & \cdots & \mathbb{Q}_{N}(k)
	\end{matrix} 
	\right] \geqslant 0 .
\end{flalign}

\begin{flalign} \label{eq:Zv}
	\mathbb{Z}(k) = \left[ \mathbb{P}(k)\otimes I \right]'\mathbb{D}(k)
	\left[ \mathbb{P}(k)\otimes I \right] \geqslant 0. 
\end{flalign}

\begin{flalign} \label{eq:Lv}
	\mathbb{L}(k) = \left[ L_{1}(k) \cdots L_{N}(k) \right].
\end{flalign}

\begin{flalign} \label{eq:a}
	a(t) = \mathbb{L}(t)\left[ \prod_{l=0}^{t-1}\mathbb{A}(l) \right] 
		\mu(0),\; t=1,\dotsc,T,  \nonumber \\
	a = [a(1) \cdots a(T) ]'.
\end{flalign}

Finally, for $ t=1,\dotsc,T$ and $1 \leqslant s \leqslant t$:
\begin{flalign} \label{eq:Bt}
	g(t,s) =  \mathbb{L}(t)\left[ \prod_{l=s}^{t-1}\mathbb{A}(l) \right] 
		\mathbb{Z}(s-1)^{\frac{1}{2}},  \nonumber \\
	b(t,s) = \frac{1}{2}\sum_{l=0}^{s-1}g(t,l+1)g(s,l+1)',  \nonumber \\
		\tilde{b}(i,j) = 
	\begin{cases}
		b(i,j) \qquad i \geqslant j \\
		b(j,i) \qquad i < j
	\end{cases}, \nonumber \\
	\tilde{\mathbb{B}} =
	\left[
	\begin{matrix}
		\tilde{b}(1,1) & \cdots & \tilde{b}(1,T)\\
		\vdots & \ddots & \vdots \\
		\tilde{b}(T,1) & \cdots & \tilde{b}(T,T)
	\end{matrix}
	\right].
\end{flalign}

% ****************************************************************************
% ******************	PREVIOUS RESULTS section
% ****************************************************************************
%
\section{Previous results} \label{pResults}

The following results represent the minimum previous knowledge we need to solve problem $PC(\nu,\beta,\alpha)$ using the optimal control law of problem $PU(\nu,\xi)$. 

We basically set the conditions and explicit formulas for the optimal control strategy of problem $PU(\nu,\xi)$ and formulas for the expected system's output and total weighted variance.
Once more, the reader is referred to \cite{alexandre} for further details and proofs.

Assumption \ref{aH} and Proposition \ref{p:aH} establish the conditions we need in order to 
state that the solution of the auxiliary problem $A(\nu, \lambda)$ will also be the solution of problem $PU(\nu,\xi)$.

Theorem \ref{t:c_law} provides the optimal control law of $PU(\nu,\xi)$, which depends on $\lambda$ as one can see from Equations  (\ref{eq:Vi}) and (\ref{eq:Hfi}), while Theorem \ref{t:lambda} establishes the identity between the parameter $\lambda$ and the input parameter $\xi$.

Proposition \ref{p:SVar} gives an explicit formula for the expected value of the output and its total weighted variance when the optimal control policy (\ref{u_k}) is applied.

\begin{assumption} \label{aH}
	For each $i=1, \dotsc, N \text{ and } k=0, \dotsc, T-1$, we have that 
	$H_{i}(k) \in Im(\mathcal{R}_{i}(k,P(k+1)))$.
\end{assumption}

\begin{prop} \label{p:aH}
	If Assumption \ref{aH} holds then
	$H_{i}(k) \in Im(\mathcal{R}_{i}(k,P(k+1)))$ 
	is satisfied for any $\lambda \in \mathbb{R}^{T}$.
\end{prop}

\begin{proof}
	See Proposition 5 in \cite{alexandre}.
\end{proof}

% ****************************************	theorem 1 - Control law
\begin{theorem} \label{t:c_law}
If Proposition \ref{p:aH} holds then an optimal control strategy for problem $PU(\nu,\xi)$ is achieved by
	\begin{flalign} \label{u_k} 
		u(k) = -\mathcal{R}_{\theta(k)}(k,P(k+1))^{\dagger} 
		\Bigl[ \mathcal{G}_{\theta(k)}(k,P(k+1))x(k) - 
		\frac{1}{2}\mathcal{H}_{\theta(k)}(k,V(k+1)) \Bigr].
	\end{flalign}
\end{theorem}

\begin{proof}
	See Theorem 1 in \cite{alexandre}.
\end{proof}

% ****************************************	theorem 2
\begin{theorem} \label{t:lambda}
	Suppose that Assumption \ref{aH} holds. If $ \tilde{\mathbb{B}} - 2 
	\tilde{\mathbb{B}} \Gamma 	
	\tilde{\mathbb{B}} > 0$ then an optimal control strategy $u^{\lambda}$ for 
	problem 	
	$PU(\nu,\xi)$ is given as in (\ref{u_k}) with
	\begin{flalign} \label{PU:lambda}
		\lambda = (I-2\Gamma\tilde{\mathbb{B}})^{-1}(\xi+2\Gamma a).
	\end{flalign}
\end{theorem}

\begin{proof}
	See Theorem 2 in \cite{alexandre}
\end{proof}

% ****************************************	proposition about Var equation
\begin{prop} \label{p:SVar}
	If the control strategy (\ref{u_k}) is applied to system (\ref{eq:system}) 
	then
	\begin{flalign} \label{eq:E_y}
		 E\bigl[ y^{u}(t) \bigr]= a(t) + \sum_{s=1}^{T}\lambda(s)
		 \tilde{b}(t,s).
	\end{flalign}

	Moreover, under Assumption \ref{aH},
	\begin{flalign} \label{eq:Svar}
		\sum_{t=1}^{T}\nu(t) Var\big[ y^{u}(t) \big] = 	
		\sum_{i=1}^{N}tr(\,P_{i}(0)Q_{i}(0)\,)
		- \sum_{t=1}^{T} \lambda(t) a(t) - \frac{1}{2} \sum_{j=1}^{T} 
		\sum_{i=1}^{T} \lambda(i) \lambda(j) \tilde{b}(i,j)   \nonumber \\
		+ \sum_{t=1}^{T} \left\{ \lambda(t) - \nu(t) \left[ a(t) + 		
		\sum_{s=1}^{T}\lambda(s)\tilde{b}(t,s) \right] \right\}
		 \left[ a(t) + \sum_{s=1}^{T}\lambda(s)\tilde{b}(t,s) \right].
	\end{flalign}
\end{prop}

Notice that the equation above can be rewritten using vectors as shown below.
	\begin{flalign} \label{eq:SvarVector}
		\sum_{t=1}^{T}\nu(t) Var\big[ y^{u}(t) \big] = 
			\lambda'\left( \frac{1}{2} I - \tilde{\mathbb{C}}' 		
			\right)\tilde{\mathbb{B}}\lambda  
			- 2 \eta'\tilde{\mathbb{B}} \lambda + c -\eta'a,
	\end{flalign}
	%
	where we define,
	\begin{flalign}	
			 c = \sum_{i=1}^{N}tr(\,P_{i}(0)Q_{i}(0)\,),
	\end{flalign}
	%
	\begin{flalign}	\label{eta}
			\eta = [a(1)\nu(1) \cdots a(T)\nu(T) ]' = \Gamma a,
	\end{flalign}
	%
	\begin{flalign}	\label{Ct}
			\tilde{\mathbb{C} } = 
			\left[
			\begin{matrix}
				\tilde{b}(1,1)\nu(1) & \dotsc & \tilde{b}(1,T)\nu(1) \\
				\vdots & \dots & \vdots \\
				\tilde{b}(T,1)\nu(T) & \dotsc & \tilde{b}(T,T)\nu(T)
			\end{matrix}
			\right] = \Gamma \tilde{\mathbb{B}}.
	\end{flalign}
\begin{proof}
	See Proposition 7 in \cite{alexandre} and our appendix \ref{app:A} for the vector formulation.
\end{proof}

% ****************************************************************************
% ******************	algorithm section
% ****************************************************************************
%
\section{Optimal control law algorithm} \label{remark:uk}
	In order to obtain an optimal control law for $PU(\nu,\xi)$, given the input risk 
	parameters $\nu$ and $\xi$, one should follow the next steps: 
	\begin{enumerate}
		\item Provide the set of assets, their returns and standard deviations;
		
		\item Set the initial conditions $x(0)$ and $\theta(0)$;
		
		\item Establish convenient $\nu$ and $\xi$ parameters according with the investor's risk preferences regarding the system's output and variance;
		
		\item Compute the Riccati Equation (\ref{eq:Pi}) backwards with 
				$P(T) = \nu(T)(L_1'L_1, \cdots, L_N'L_N)$ and $\nu(0)=0$;
	
		\item Obtain $\mathcal{K}$ along with $\mathcal{G}$ and $\mathcal{R}$ using 
				Equations (\ref{eq:Gi}), (\ref{eq:Ri}), and (\ref{eq:Ki});
	
		\item Compute $\tilde{\mathbb{B}}$ using the set of equations from 
				(\ref{eq:gamma}) to (\ref{eq:Bt}) in order to obtain $\lambda$ with 
				(\ref{PU:lambda});
		\item Compute $\lambda$ using Equation (\ref{PU:lambda});

		\item Calculate $V(k)$ backwards using Equation (\ref{eq:Vi}) 
			and $V(T) = \lambda(T)(L_1, \cdots, L_N)$;
	
		\item Compute $\mathcal{H}(k)$ using (\ref{eq:Hfi});
			
		\item Finally, apply Equation (\ref{u_k}) to get the optimal control law, $u(k)$, for each $k = 0, \cdots, T-1$. 
	\end{enumerate}
	
In Chapter \ref{chap:res}, we will show how to obtain the optimal control law for Problem \ref{PC3}, $PC(\nu,\beta,\alpha)$, using the algorithm above by properly fixing the parameter $\xi$ in terms of $\beta$ and $\alpha$.


% ****************************************************************************
% ******************	algorithm section
% ****************************************************************************
%
\section{Methodology} \label{sec:method}

Our goal is to identify the explicit control strategy that maximizes the expected system's output while keeping the total weighted variance of the output restricted by a fixed value, $\alpha$.
This will be achieved here by proving that the optimal control law of Problem (\ref{PC3}), $PC(\nu,\beta,\alpha)$,  can be obtained through the optimal solution of the Unconstrained Problem (\ref{PU}), which in turn is achieved through the optimal solution of the Auxiliary Problem (\ref{AP}), $A(\nu, \lambda)$.
%, and the identity between $\xi$ and $\lambda$ given by Equation (\ref{PU:lambda}).

We start by considering the system as defined by Equations (\ref{eq:system}) and (\ref{eq:output}) and which are reproduced here.
\begin{flalign*} %\label{eq:system}
	x(k+1) ={}& \biggl[\: \bar{A}_{\theta(k)}(k)\;+\; 	
		\sum^{\varepsilon^{x}}_{s=1} \tilde{A}_{\theta(k),s}(k)w^{x}_{s}(k) 
		\:\biggr]x(k) 
	+\biggl[\:\bar{B}_{\theta(k)}(k)\;+\;\sum^{\varepsilon^{u}}_{s=1} 					\tilde{B}_{\theta(k),s}(k)w^{u}_{s}(k)\:\biggr]u(k), & \nonumber \\
	 x(0) ={}& x_{0}, \; \theta(0) = \theta_{0}, \text{ and }&\\
	 y(t)={}& L_{\theta(t)}(t)x(t), &
\end{flalign*}
where $k = 0,1,\cdots, T-1$ and $t = 1,\cdots, T$. See Section \ref{notation} for further details about the notations and definitions regarding our system.

In order to ease the reading, we also reproduce below the formal definitions of $PC(\nu,\beta,\alpha)$, $PU(\nu,\xi)$, and $A(\nu, \lambda)$ considering the system's output given by Equation (\ref{eq:output}).
%
\begin{flalign*} %\label{PC3}
	& PC(\nu,\beta,\alpha): \max_{u \in \mathbb{U}} \sum_{t=1}^{T} \biggl[ 	
	\beta(t)E\big[ y^{u}(t) \big] \biggr], 
	 \text{ subject to} \; \sum_{t=1}^{T} \nu(t)Var\big[ y^{u}(t) \big] \leqslant \alpha,
\end{flalign*}
\begin{flalign*} %\label{PU}
	PU(\nu,\xi):\; \min_{u \in \mathbb{U}} \sum_{t=1}^{T} \biggl[ \nu(t)Var\big[ y^{u}(t) \big] 
	 -\xi(t)E\big[ y^{u}(t) \big] \biggr],
\end{flalign*}
and
\begin{flalign*} 
	 A(\nu, \lambda):=\; \min_{ u \in \mathbb{U} } E \Biggl\{ \sum_{t=1}^{T}\biggl[ \nu(t)y^{u}	
	(t)^{2} - \lambda(t)y^{u}(t) \biggr] \Biggr\},
\end{flalign*}
where, $\nu=[\nu(1) \cdots \nu(T) ]',\; \nu(t) \geqslant 0$, is the input parameter associated with the variance of the system's output in all three problems, $\alpha \geqslant 0$ is the maximum total weighted variance of the system's output in the $PC(\nu,\beta,\alpha)$ problem, 
and $ \beta = [\beta(1) \cdots \beta(T)]', \; \beta(t) \geqslant 0$,  $\xi=[\xi(1) \cdots \xi(T) ]',\;\xi(t) \geqslant 0$, and $\lambda=[\lambda(1) \cdots \lambda(T) ]',\; \lambda(t) \geqslant 0$,  are the input parameters associated with the system's output in the $PC(\nu,\beta,\alpha)$, $PU(\nu,\xi)$, and $A(\nu, \lambda)$ problems, respectively.

In order to use the optimal control formulation of $PU(\nu,\xi)$ that complies with the restriction of $PC(\nu,\beta,\alpha)$, we will fix the parameter $\xi$ through an appropriate relation between $\xi$, $\beta$, and $\alpha$.
In this way, given $\nu$, $\beta$, and $\alpha$, one could compute $\xi$ with the formulation we will develop here and, then, obtain $\lambda$ with Equation (\ref{PU:lambda}) and the optimal control using the algorithm described in Section \ref{remark:uk}. 
